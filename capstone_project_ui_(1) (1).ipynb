{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow matplotlib split-folders gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aREQYZZQ95yS",
        "outputId": "1dd3fe87-791e-4c55-a87c-16369090dc72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjrRynT1_aXw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72bdcf85"
      },
      "source": [
        "Let's test the model with a sample image from the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lmFQByBjJ6z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q tensorflow matplotlib split-folders gradio==4.8.8\n",
        "print(\"âœ… All packages installed\")\n"
      ],
      "metadata": {
        "id": "IHX_w8eOJ36x",
        "outputId": "84a7f828-04f2-4b6a-95c6-24188b8c3f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following yanked versions: 2.8.0, 3.0.7, 3.1.2, 3.13.1, 3.45.0b9, 3.45.0b10, 3.45.0b11, 3.45.0b12, 3.45.0b13, 4.0.0b15, 4.7.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement gradio==4.8.8 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.4.0, 0.4.1, 0.4.2, 0.4.4, 0.5.0, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.9.5, 0.9.6, 0.9.7, 0.9.8, 0.9.9.2, 0.9.9.3, 0.9.9.5, 0.9.9.6, 0.9.9.7, 0.9.9.8, 0.9.9.9, 0.9.9.9.2, 1.0.0a1, 1.0.0a3, 1.0.0a4, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.1.8, 1.1.8.1, 1.1.9, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.4.0, 1.4.2, 1.4.3, 1.4.4, 1.5.0, 1.5.1, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.4, 1.7.5, 1.7.6, 1.7.7, 2.0.0, 2.0.1, 2.0.2, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10, 2.1.0, 2.1.1, 2.1.2, 2.1.4, 2.1.6, 2.1.7, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.2.7, 2.2.8, 2.2.9a0, 2.2.9a2, 2.2.10, 2.2.11, 2.2.12, 2.2.13, 2.2.14, 2.2.15, 2.3.0a0, 2.3.0b99, 2.3.0b101, 2.3.0b102, 2.3.0, 2.3.3, 2.3.4, 2.3.5b0, 2.3.5, 2.3.6, 2.3.7b0, 2.3.7b1, 2.3.7b2, 2.3.7, 2.3.8b0, 2.3.9, 2.4.0a0, 2.4.0, 2.4.1, 2.4.2, 2.4.4, 2.4.5, 2.4.6, 2.4.7b0, 2.4.7b2, 2.4.7b3, 2.4.7b4, 2.4.7b5, 2.4.7b6, 2.4.7b7, 2.4.7b8, 2.4.7b9, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.5.8a0, 2.6.0, 2.6.1a0, 2.6.1b0, 2.6.1b3, 2.6.1, 2.6.2, 2.6.3, 2.6.4b0, 2.6.4b2, 2.6.4b3, 2.6.4, 2.7.0a101, 2.7.0a102, 2.7.0b70, 2.7.0, 2.7.5, 2.7.5.1, 2.7.5.2b0, 2.7.5.2, 2.8.0a100, 2.8.0b0, 2.8.0b2, 2.8.0b3, 2.8.0b4, 2.8.0b5, 2.8.0b6, 2.8.0b10, 2.8.0b12, 2.8.0b20, 2.8.0b22, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.8.5, 2.8.6, 2.8.7, 2.8.8, 2.8.9, 2.8.10, 2.8.11, 2.8.12, 2.8.13, 2.8.14, 2.9.0b0, 2.9.0b1, 2.9.0b2, 2.9.0b3, 2.9.0b5, 2.9.0b6, 2.9.0b7, 2.9.0b8, 2.9.0b9, 2.9.0b10, 2.9b11, 2.9b12, 2.9b13, 2.9b14, 2.9b15, 2.9b20, 2.9b21, 2.9b22, 2.9b23, 2.9b24, 2.9b25, 2.9b26, 2.9b27, 2.9b28, 2.9b30, 2.9b31, 2.9b32, 2.9b33, 2.9b40, 2.9b48, 2.9b50, 2.9.0, 2.9.0.1, 2.9.1, 2.9.2, 2.9.3, 2.9.4, 3.0b0, 3.0b1, 3.0b2, 3.0b5, 3.0b6, 3.0b8, 3.0b9, 3.0b10, 3.0, 3.0.1b120, 3.0.1b121, 3.0.1b300, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.0.6b1, 3.0.6b2, 3.0.6b3, 3.0.6, 3.0.8b1, 3.0.8, 3.0.9b10, 3.0.9b11, 3.0.9b20, 3.0.9, 3.0.10b2, 3.0.10b16, 3.0.10, 3.0.11b1, 3.0.11, 3.0.12, 3.0.13b13, 3.0.13b15, 3.0.13b100, 3.0.13, 3.0.14, 3.0.15, 3.0.16, 3.0.17, 3.0.18b0, 3.0.18, 3.0.19b0, 3.0.19b1, 3.0.19b2, 3.0.19, 3.0.20.dev0, 3.0.20, 3.0.21, 3.0.22, 3.0.23.dev1, 3.0.23, 3.0.24, 3.0.25, 3.0.26, 3.1.0, 3.1.1, 3.1.3a0, 3.1.3a2, 3.1.3a3, 3.1.3a4, 3.1.3a5, 3.1.3, 3.1.4b0, 3.1.4b1, 3.1.4b2, 3.1.4b3, 3.1.4b4, 3.1.4b5, 3.1.4, 3.1.5b1, 3.1.5b2, 3.1.5b3, 3.1.5b4, 3.1.5b5, 3.1.5b7, 3.1.5b8, 3.1.5b9, 3.1.5b10, 3.1.5, 3.1.6b1, 3.1.6, 3.1.7, 3.1.8b0, 3.1.8b2, 3.1.8b3, 3.1.8b4, 3.1.8b6, 3.2, 3.2.1b0, 3.2.1b1, 3.2.1b2, 3.3b0, 3.3b1, 3.3, 3.3.1, 3.4b0, 3.4b1, 3.4b2, 3.4b3, 3.4b5, 3.4, 3.4.1, 3.5, 3.6.0b1, 3.6.0b2, 3.6.0b3, 3.6.0b7, 3.6.0b10, 3.6, 3.7, 3.8b1, 3.8b2, 3.8, 3.8.1.dev1, 3.8.1, 3.8.2, 3.9, 3.9.1, 3.10.0, 3.10.1, 3.11.0, 3.12.0b1, 3.12.0b2, 3.12.0b3, 3.12.0b6, 3.12.0b7, 3.12.0, 3.13.0b1, 3.13.0, 3.13.1b0, 3.13.1b1, 3.13.1b2, 3.13.2, 3.14.0a1, 3.14.0, 3.15.0, 3.16.0, 3.16.1b1, 3.16.1, 3.16.2, 3.17.0, 3.17.1b1, 3.17.1b2, 3.17.1, 3.18.0, 3.18.1b1, 3.18.1b2, 3.18.1b3, 3.18.1b4, 3.18.1b5, 3.18.1b6, 3.18.1b7, 3.19.0, 3.19.1, 3.20.0b1, 3.20.0b2, 3.20.0, 3.20.1, 3.21.0, 3.22.0, 3.22.1b1, 3.22.1, 3.23.0, 3.23.1b1, 3.23.1b2, 3.23.1b3, 3.24.0, 3.24.1, 3.25.0, 3.25.1b1, 3.25.1b2, 3.26.0, 3.27.0, 3.28.0, 3.28.1, 3.28.2, 3.28.3, 3.28.4b0, 3.29.0, 3.30.0, 3.31.0, 3.32.0, 3.33.0, 3.33.1, 3.34.0, 3.35.0, 3.35.1, 3.35.2, 3.36.0, 3.36.1, 3.37.0, 3.38.0, 3.39.0, 3.40.0, 3.40.1, 3.41.0, 3.41.1, 3.41.2, 3.42.0, 3.43.0, 3.43.1, 3.43.2, 3.44.0, 3.44.1, 3.44.2, 3.44.3, 3.44.4, 3.45.0b0, 3.45.0, 3.45.1, 3.45.2, 3.46.0, 3.46.1, 3.47.0, 3.47.1, 3.48.0, 3.49.0, 3.50.0, 3.50.1, 3.50.2, 4.0.0, 4.0.1, 4.0.2, 4.1.0, 4.1.1, 4.1.2, 4.2.0, 4.3.0, 4.4.0, 4.4.1, 4.5.0, 4.7.1, 4.8.0, 4.9.0, 4.9.1, 4.10.0, 4.11.0, 4.12.0, 4.13.0, 4.14.0, 4.15.0, 4.16.0, 4.17.0, 4.18.0, 4.19.0, 4.19.1, 4.19.2, 4.20.0, 4.20.1, 4.21.0, 4.22.0, 4.23.0, 4.24.0, 4.25.0, 4.26.0, 4.27.0, 4.28.0, 4.28.1, 4.28.2, 4.28.3, 4.29.0, 4.31.0, 4.31.1, 4.31.2, 4.31.3, 4.31.4, 4.31.5, 4.32.0, 4.32.1, 4.32.2, 4.33.0, 4.35.0, 4.36.0, 4.36.1, 4.37.1, 4.37.2, 4.38.0, 4.38.1, 4.39.0, 4.40.0, 4.41.0, 4.42.0, 4.43.0, 4.44.0, 4.44.1, 5.0.0b1, 5.0.0b5, 5.0.0b6, 5.0.0b7, 5.0.0b8, 5.0.0b9, 5.0.0b10, 5.0.0, 5.0.1, 5.0.2, 5.1.0, 5.3.0, 5.4.0, 5.5.0, 5.6.0, 5.7.0, 5.7.1, 5.8.0, 5.9.0, 5.9.1, 5.10.0, 5.11.0, 5.12.0, 5.13.0, 5.13.1, 5.13.2, 5.14.0, 5.15.0, 5.16.0, 5.16.1, 5.16.2, 5.17.0, 5.17.1, 5.18.0, 5.19.0, 5.20.0, 5.20.1, 5.21.0, 5.22.0, 5.23.0, 5.23.1, 5.23.2, 5.23.3, 5.24.0, 5.25.0, 5.25.1, 5.25.2, 5.26.0, 5.27.0, 5.27.1, 5.28.0, 5.29.0, 5.29.1, 5.30.0, 5.31.0, 5.32.0, 5.32.1, 5.33.0, 5.33.1, 5.33.2, 5.34.0, 5.34.1, 5.34.2, 5.35.0, 5.36.2, 5.37.0, 5.38.0, 5.38.1, 5.38.2, 5.39.0, 5.40.0, 5.41.0, 5.41.1, 5.42.0, 5.43.0, 5.43.1, 5.44.0, 5.44.1, 5.45.0, 5.46.0, 5.46.1, 5.47.0, 5.47.1, 5.47.2, 5.48.0, 5.49.0, 5.49.1, 6.0.0.dev0, 6.0.0.dev1, 6.0.0.dev3, 6.0.0.dev4)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gradio==4.8.8\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… All packages installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, tensorflow as tf\n",
        "\n",
        "dataset_url = \"https://github.com/Bangkit-JKT2-D/fruits-fresh-rotten-classification/archive/refs/heads/master.zip\"\n",
        "zip_path = tf.keras.utils.get_file(\"fruits_dataset.zip\", origin=dataset_url, extract=True)\n",
        "\n",
        "base_parent = os.path.dirname(zip_path)\n",
        "base_dir = None\n",
        "for root, dirs, files in os.walk(base_parent):\n",
        "    for d in dirs:\n",
        "        if \"fruits-fresh-rotten-classification\" in d:\n",
        "            base_dir = os.path.join(root, d)\n",
        "            break\n",
        "    if base_dir:\n",
        "        break\n",
        "\n",
        "if not base_dir:\n",
        "    raise FileNotFoundError(\"âŒ Dataset folder not found\")\n",
        "\n",
        "print(\"Dataset found at:\", base_dir)\n"
      ],
      "metadata": {
        "id": "USXKhY6dJ41T",
        "outputId": "c61e3d87-2ef7-44c4-8f0a-4eb22432f312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Bangkit-JKT2-D/fruits-fresh-rotten-classification/archive/refs/heads/master.zip\n",
            "1927667712/Unknown \u001b[1m77s\u001b[0m 0us/stepDataset found at: /root/.keras/datasets/fruits_dataset_extracted/fruits-fresh-rotten-classification-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "merged_dir = \"binary_fruit_dataset\"\n",
        "fresh_dir = os.path.join(merged_dir, \"fresh\")\n",
        "spoiled_dir = os.path.join(merged_dir, \"spoiled\")\n",
        "os.makedirs(fresh_dir, exist_ok=True)\n",
        "os.makedirs(spoiled_dir, exist_ok=True)\n",
        "\n",
        "fresh_count = spoiled_count = 0\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    folder = os.path.basename(root).lower()\n",
        "    imgs = glob.glob(os.path.join(root, \"*.jpg\")) + glob.glob(os.path.join(root, \"*.png\"))\n",
        "    for img in imgs:\n",
        "        if \"fresh\" in folder:\n",
        "            shutil.copy(img, os.path.join(fresh_dir, os.path.basename(img)))\n",
        "            fresh_count += 1\n",
        "        elif \"rotten\" in folder or \"spoiled\" in folder:\n",
        "            shutil.copy(img, os.path.join(spoiled_dir, os.path.basename(img)))\n",
        "            spoiled_count += 1\n",
        "\n",
        "print(f\"âœ… Fresh: {fresh_count} | Spoiled: {spoiled_count}\")\n"
      ],
      "metadata": {
        "id": "jKy2r98fJ4x3",
        "outputId": "5f02efb4-230e-4105-b0fd-029872859d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fresh: 5904 | Spoiled: 7695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(merged_dir, output=\"binary_split\", seed=42, ratio=(.8, .1, .1))\n",
        "print(\"âœ… Split done (binary_split/train, val, test)\")\n"
      ],
      "metadata": {
        "id": "cs6QNCoQJ4vd",
        "outputId": "66ab95c4-a863-4e2b-e5d2-6faa59e0ba17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 13599 files [00:16, 822.53 files/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Split done (binary_split/train, val, test)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (150,150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    \"binary_split/train\", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    \"binary_split/val\", target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
        "\n",
        "print(\"Train:\", train_gen.samples, \" Val:\", val_gen.samples)\n"
      ],
      "metadata": {
        "id": "Uq3zHP2KJ4s6",
        "outputId": "84e72c8b-ffee-435f-f2ba-9b9d6565f815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10879 images belonging to 2 classes.\n",
            "Found 1359 images belonging to 2 classes.\n",
            "Train: 10879  Val: 1359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "base = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(150,150,3), include_top=False, weights='imagenet')\n",
        "base.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "FLL7IEodJ4qF",
        "outputId": "47a9444d-1c46-44cb-93f8-f792df54f7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3191289971.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = tf.keras.applications.MobileNetV2(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m163,968\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,081\u001b[0m (9.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,081</span> (9.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,097\u001b[0m (641.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,097</span> (641.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS)\n",
        "print(\"âœ… Training finished\")\n"
      ],
      "metadata": {
        "id": "-S3So8iNJ4ng",
        "outputId": "711c6cde-e25e-49fb-c8a2-1671aab14f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m340/340\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 400ms/step - accuracy: 0.9414 - loss: 0.1462 - val_accuracy: 0.9448 - val_loss: 0.1505\n",
            "Epoch 2/5\n",
            "\u001b[1m340/340\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 319ms/step - accuracy: 0.9742 - loss: 0.0720 - val_accuracy: 0.9890 - val_loss: 0.0380\n",
            "Epoch 3/5\n",
            "\u001b[1m340/340\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 321ms/step - accuracy: 0.9818 - loss: 0.0494 - val_accuracy: 0.9912 - val_loss: 0.0297\n",
            "Epoch 4/5\n",
            "\u001b[1m340/340\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 317ms/step - accuracy: 0.9830 - loss: 0.0426 - val_accuracy: 0.9845 - val_loss: 0.0432\n",
            "Epoch 5/5\n",
            "\u001b[1m340/340\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 316ms/step - accuracy: 0.9857 - loss: 0.0370 - val_accuracy: 0.9610 - val_loss: 0.1065\n",
            "âœ… Training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    \"binary_split/test\", target_size=IMG_SIZE, batch_size=1, class_mode='binary')\n",
        "\n",
        "loss, acc = model.evaluate(test_gen, steps=min(50, test_gen.samples))\n",
        "print(f\"Loss={loss:.4f}, Accuracy={acc:.4f}\")\n",
        "\n",
        "model.save(\"fruit_fresh_spoiled_model.h5\")\n",
        "print(\"âœ… Model saved\")\n"
      ],
      "metadata": {
        "id": "x0frXSfAJ4kz",
        "outputId": "bd2d3bb9-9c86-4fd3-e5bd-0f0a57823bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1361 images belonging to 2 classes.\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss=0.0149, Accuracy=1.0000\n",
            "âœ… Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# If you already trained earlier, this reloads saved model\n",
        "model = load_model(\"fruit_fresh_spoiled_model.h5\")\n",
        "\n",
        "def classify_fruit(img):\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img = Image.fromarray(img)\n",
        "    img = img.convert(\"RGB\").resize((150,150))\n",
        "    x = np.expand_dims(np.array(img)/255.0, axis=0)\n",
        "    pred = float(model.predict(x)[0][0])\n",
        "    label = \"ğŸ Fresh\" if pred < 0.5 else \"ğŸ‚ Spoiled\"\n",
        "    conf = pred if pred >= 0.5 else 1 - pred\n",
        "    return {label: float(conf)}\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify_fruit,\n",
        "    inputs=gr.Image(sources=[\"webcam\", \"upload\"], label=\"ğŸ“¸ Use Laptop Camera\"),\n",
        "    outputs=gr.Label(),\n",
        "    title=\"ğŸ Fresh vs Spoiled Fruit Detector\",\n",
        "    description=\"Open your laptop camera and scan a fruit.\"\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "x4Q9khx0J4h-",
        "outputId": "88be535e-20a9-4130-9eb3-406ccdbe50de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c345d9eb10e991d2de.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c345d9eb10e991d2de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDkDEy7WJ4fI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e053bd8c"
      },
      "source": [
        "# Task\n",
        "Install Streamlit and `pyngrok` for building and deploying the web application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11d672a7"
      },
      "source": [
        "## Install Streamlit and NGROK\n",
        "\n",
        "### Subtask:\n",
        "Install the `streamlit` and `pyngrok` libraries required for building and deploying the web application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a0339c0"
      },
      "source": [
        "**Reasoning**:\n",
        "To achieve the subtask, I will install the `streamlit` and `pyngrok` libraries using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ad47447",
        "outputId": "41b6ed5d-3e5b-41c1-e0c3-cf53d4a40cb7"
      },
      "source": [
        "pip install streamlit pyngrok"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok, pydeck, streamlit\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [streamlit]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pydeck-0.9.1 pyngrok-7.5.0 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587120cb"
      },
      "source": [
        "## Create Streamlit Application\n",
        "\n",
        "### Subtask:\n",
        "Write the Python code for the Streamlit application. This will include loading the `fruit_fresh_spoiled_model.h5` model, defining the prediction function to classify fruits and provide confidence scores, and setting up the user interface with an image input (upload and/or webcam) and output for the classification result and confidence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9542dac8"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a new Python file named `streamlit_app.py` containing the Streamlit application code. This file will import required libraries, load the pre-trained model, define the prediction function for fruit classification, and set up the Streamlit UI for image upload and displaying predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc65c21",
        "outputId": "41157cae-6675-4df2-fcc6-847c25afb3a4"
      },
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Load the pre-trained model\n",
        "# Ensure the model file is accessible (e.g., in the same directory or specified path)\n",
        "MODEL_PATH = 'fruit_fresh_spoiled_model.h5'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_my_model():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "model = load_my_model()\n",
        "\n",
        "IMG_SIZE = (150, 150)\n",
        "\n",
        "def classify_fruit_streamlit(img):\n",
        "    \"\"\"Predicts whether a fruit image is fresh or spoiled.\"\"\"\n",
        "    # Ensure image is in PIL format for consistent processing\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    # Resize and convert to RGB\n",
        "    img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "\n",
        "    # Normalize and expand dimensions\n",
        "    x = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(x)[0][0]\n",
        "\n",
        "    # Determine label and confidence\n",
        "    if prediction < 0.5:\n",
        "        label = \"ğŸ Fresh\"\n",
        "        confidence = 1 - prediction\n",
        "    else:\n",
        "        label = \"ğŸ‚ Spoiled\"\n",
        "        confidence = prediction\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Streamlit App Layout\n",
        "st.title(\"ğŸ Fresh vs Spoiled Fruit Detector\")\n",
        "st.write(\"Upload an image of a fruit to classify it as fresh or spoiled.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    # Make prediction\n",
        "    label, confidence = classify_fruit_streamlit(image)\n",
        "\n",
        "    # Display results\n",
        "    st.write(\"### Prediction:\")\n",
        "    if \"Fresh\" in label:\n",
        "        st.success(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n",
        "    else:\n",
        "        st.error(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8e5682a"
      },
      "source": [
        "## Configure NGROK Tunnel\n",
        "\n",
        "### Subtask:\n",
        "Initialize and authenticate NGROK using the provided NGROK authentication token to create a public URL for the Streamlit application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8a24c9"
      },
      "source": [
        "### Get your NGROK Authentication Token\n",
        "\n",
        "1.  **Sign up/Log in to ngrok**: If you don't have an ngrok account, sign up at [ngrok.com](https://ngrok.com). If you do, log in.\n",
        "2.  **Access your Dashboard**: Once logged in, navigate to your ngrok dashboard.\n",
        "3.  **Find your Auth Token**: Your authentication token will be prominently displayed on the dashboard, usually under 'Your Authtoken'. It typically looks like `2k2sV4F2o3eW2p5x0y7fX2dZ0q3aG7gJ1w2Q6z4r5D6F9j9C0N`. Copy this token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bd80b1c"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `streamlit` and `pyngrok` libraries are installed, the next step is to import `pyngrok` and set the authentication token using `ngrok.set_auth_token()`. This will allow `pyngrok` to establish a secure tunnel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efe1fcb0",
        "outputId": "75f75891-1085-47bc-fe39-c2911be796f2"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# IMPORTANT: Replace 'YOUR_NGROK_AUTH_TOKEN' with your actual ngrok authentication token\n",
        "NGROK_AUTH_TOKEN = '34kbOT6L1mXAIZVVQc5MxsSN22g_4bUZKAtvNLpKRcbyY3ncY'\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "print(\"âœ… ngrok authentication token set\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ngrok authentication token set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4da6f44d"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the ngrok authentication token is set, the next step is to start the Streamlit application and then establish an ngrok tunnel to expose it to the internet. This will make the Streamlit app accessible via a public URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deade9be",
        "outputId": "1fd19eac-f067-493e-de6a-a87db233553e"
      },
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Load the pre-trained model\n",
        "# Ensure the model file is accessible (e.g., in the same directory or specified path)\n",
        "MODEL_PATH = 'fruit_fresh_spoiled_model.h5'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_my_model():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "model = load_my_model()\n",
        "\n",
        "IMG_SIZE = (150, 150)\n",
        "\n",
        "def classify_fruit_streamlit(img):\n",
        "    \"\"\"Predicts whether a fruit image is fresh or spoiled.\"\"\"\n",
        "    # Ensure image is in PIL format for consistent processing\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    # Resize and convert to RGB\n",
        "    img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "\n",
        "    # Normalize and expand dimensions\n",
        "    x = np.expand_dims(np.array(img) / 255.0, axis=0);\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(x)[0][0]\n",
        "\n",
        "    # Determine label and confidence\n",
        "    if prediction < 0.5:\n",
        "        label = \"ğŸ Fresh\"\n",
        "        confidence = 1 - prediction\n",
        "    else:\n",
        "        label = \"ğŸ‚ Spoiled\"\n",
        "        confidence = prediction\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Streamlit App Layout\n",
        "st.title(\"ğŸ Fresh vs Spoiled Fruit Detector\")\n",
        "st.write(\"Upload an image of a fruit or use your camera to classify it as fresh or spoiled.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image from your files...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "camera_image = st.camera_input(\"Take a picture with your camera\")\n",
        "\n",
        "image_to_process = None\n",
        "if uploaded_file is not None:\n",
        "    image_to_process = Image.open(uploaded_file)\n",
        "elif camera_image is not None:\n",
        "    image_to_process = Image.open(camera_image)\n",
        "\n",
        "if image_to_process is not None:\n",
        "    # Display the selected image\n",
        "    st.image(image_to_process, caption='Selected Image', use_container_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    # Make prediction\n",
        "    label, confidence = classify_fruit_streamlit(image_to_process)\n",
        "\n",
        "    # Display results\n",
        "    st.write(\"### Prediction:\")\n",
        "    if \"Fresh\" in label:\n",
        "        st.success(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n",
        "    else:\n",
        "        st.error(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kill any running streamlit apps"
      ],
      "metadata": {
        "id": "BiWvxtHr3tRi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3007ddbf",
        "outputId": "c36e9e28-a844-4255-87aa-98281bbf8dd2"
      },
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "/* General Body and Main Container Styling for Dark Theme */\n",
        "body {\n",
        "    background-color: #1a1a1a; /* Dark background */\n",
        "    color: #e0e0e0; /* Light text */\n",
        "    font-family: 'Roboto', sans-serif; /* Elegant font, fallback to sans-serif */\n",
        "}\n",
        "\n",
        ".main .block-container {\n",
        "    padding-top: 2rem;\n",
        "    padding-bottom: 2rem;\n",
        "    padding-left: 1rem;\n",
        "    padding-right: 1rem;\n",
        "    max-width: 700px; /* Limit width for centered content */\n",
        "    margin: auto; /* Center content */\n",
        "}\n",
        "\n",
        "/* Header Styling */\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #4CAF50; /* Eye-catching green for headers */\n",
        "    font-weight: bold;\n",
        "    text-align: center; /* Center headers */\n",
        "    padding-bottom: 0.5rem;\n",
        "    border-bottom: 2px solid #333; /* Subtle line below headers */\n",
        "    margin-bottom: 1.5rem;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".stButton>button {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    border-radius: 8px;\n",
        "    border: none;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
        "    transition: all 0.3s ease-in-out;\n",
        "    width: 100%; /* Make buttons span full width */\n",
        "    margin-top: 1rem;\n",
        "}\n",
        "\n",
        ".stButton>button:hover {\n",
        "    background-color: #5cb85c;\n",
        "    box-shadow: 0 6px 12px rgba(0, 255, 0, 0.4); /* Green glow effect */\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        "\n",
        "/* File Uploader and Camera Input Preview Styling */\n",
        ".stFileUploader, .stCameraInput {\n",
        "    border: 2px dashed #4CAF50;\n",
        "    border-radius: 12px;\n",
        "    padding: 20px;\n",
        "    text-align: center;\n",
        "    background-color: #2a2a2a;\n",
        "    transition: all 0.3s ease;\n",
        "    margin-bottom: 1.5rem;\n",
        "}\n",
        "\n",
        ".stFileUploader:hover, .stCameraInput:hover {\n",
        "    background-color: #3a3a3a;\n",
        "    border-color: #66bb6a;\n",
        "}\n",
        "\n",
        ".stImage { /* Style for displayed images */\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.5);\n",
        "    margin: 1.5rem auto; /* Center image and provide space */\n",
        "    display: block; /* Ensure margin auto works */\n",
        "    max-width: 100%;\n",
        "    height: auto;\n",
        "}\n",
        "\n",
        "/* Text and general elements */\n",
        "p, label, .stMarkdown, .css-1jc7o2r, .css-1l0bqyk, .css-1vq4p4u, .css-1qxtsq5, .css-1d391kg {\n",
        "    color: #c0c0c0;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "\n",
        "/* Success/Error messages */\n",
        ".stAlert {\n",
        "    border-radius: 8px;\n",
        "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "}\n",
        ".stAlert.success {\n",
        "    background-color: #d4edda;\n",
        "    color: #155724;\n",
        "}\n",
        ".stAlert.error {\n",
        "    background-color: #f8d7da;\n",
        "    color: #721c24;\n",
        "}\n",
        "\n",
        "/* Streamlit's main content area */\n",
        ".stApp {\n",
        "    background-color: #1a1a1a;\n",
        "}\n",
        "\n",
        "/* Responsiveness */\n",
        "@media (max-width: 768px) {\n",
        "    .main .block-container {\n",
        "        padding-left: 0.5rem;\n",
        "        padding-right: 0.5rem;\n",
        "    }\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load the pre-trained model\n",
        "# Ensure the model file is accessible (e.g., in the same directory or specified path)\n",
        "MODEL_PATH = 'fruit_fresh_spoiled_model.h5'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_my_model():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "model = load_my_model()\n",
        "\n",
        "IMG_SIZE = (150, 150)\n",
        "\n",
        "def classify_fruit_streamlit(img):\n",
        "    \"\"\"Predicts whether a fruit image is fresh or spoiled.\"\"\"\n",
        "    # Ensure image is in PIL format for consistent processing\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    # Resize and convert to RGB\n",
        "    img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "\n",
        "    # Normalize and expand dimensions\n",
        "    x = np.expand_dims(np.array(img) / 255.0, axis=0);\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(x)[0][0]\n",
        "\n",
        "    # Determine label and confidence\n",
        "    if prediction < 0.5:\n",
        "        label = \"ğŸ Fresh\"\n",
        "        confidence = 1 - prediction\n",
        "    else:\n",
        "        label = \"ğŸ‚ Spoiled\"\n",
        "        confidence = prediction\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Streamlit App Layout\n",
        "st.title(\"ğŸ Fresh vs Spoiled Fruit Detector\")\n",
        "st.write(\"Upload an image of a fruit or use your camera to classify it as fresh or spoiled.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image from your files...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "camera_image = st.camera_input(\"Take a picture with your camera\")\n",
        "\n",
        "image_to_process = None\n",
        "if uploaded_file is not None:\n",
        "    image_to_process = Image.open(uploaded_file)\n",
        "elif camera_image is not None:\n",
        "    image_to_process = Image.open(camera_image)\n",
        "\n",
        "if image_to_process is not None:\n",
        "    # Display the selected image\n",
        "    st.image(image_to_process, caption='Selected Image', use_container_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    # Make prediction\n",
        "    label, confidence = classify_fruit_streamlit(image_to_process)\n",
        "\n",
        "    # Display results\n",
        "    st.write(\"### Prediction:\")\n",
        "    if \"Fresh\" in label:\n",
        "        st.success(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n",
        "    else:\n",
        "        st.error(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9a43f1",
        "outputId": "25085f5b-e625-4562-ac94-1e99d803ae5c"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "# Find and kill any processes named 'streamlit'\n",
        "try:\n",
        "    # List all processes and filter for streamlit\n",
        "    # os.kill is for a specific PID, ps aux | grep is better for finding by name\n",
        "    # This is a common way to kill previous streamlit processes in a Colab-like environment\n",
        "    output = subprocess.check_output(['ps', 'aux']).decode('utf-8')\n",
        "    for line in output.splitlines():\n",
        "        if 'streamlit run' in line and 'python' in line:\n",
        "            pid = int(line.split()[1])\n",
        "            subprocess.run(['kill', '-9', str(pid)])\n",
        "            print(f\"Killed Streamlit process with PID: {pid}\")\n",
        "except Exception as e:\n",
        "    print(f\"No Streamlit processes found to kill or an error occurred: {e}\")\n",
        "\n",
        "# Also kill any ngrok processes\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "print(\"âœ… ngrok processes killed.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ngrok processes killed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "444c091e",
        "outputId": "ba88b0a7-8039-4343-ede0-df32d944e0a8"
      },
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "/* General Body and Main Container Styling for Dark Theme */\n",
        "body {\n",
        "    background-color: #1a1a1a; /* Dark background */\n",
        "    color: #e0e0e0; /* Light text */\n",
        "    font-family: 'Roboto', sans-serif; /* Elegant font, fallback to sans-serif */\n",
        "}\n",
        "\n",
        ".main .block-container {\n",
        "    padding-top: 2rem;\n",
        "    padding-bottom: 2rem;\n",
        "    padding-left: 1rem;\n",
        "    padding-right: 1rem;\n",
        "    max-width: 700px; /* Limit width for centered content */\n",
        "    margin: auto; /* Center content */\n",
        "}\n",
        "\n",
        "/* Header Styling */\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    color: #4CAF50; /* Eye-catching green for headers */\n",
        "    font-weight: bold;\n",
        "    text-align: center; /* Center headers */\n",
        "    padding-bottom: 0.5rem;\n",
        "    border-bottom: 2px solid #333; /* Subtle line below headers */\n",
        "    margin-bottom: 1.5rem;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".stButton>button {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    border-radius: 8px;\n",
        "    border: none;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    cursor: pointer;\n",
        "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
        "    transition: all 0.3s ease-in-out;\n",
        "    width: 100%; /* Make buttons span full width */\n",
        "    margin-top: 1rem;\n",
        "}\n",
        "\n",
        ".stButton>button:hover {\n",
        "    background-color: #5cb85c;\n",
        "    box-shadow: 0 6px 12px rgba(0, 255, 0, 0.4); /* Green glow effect */\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        "\n",
        "/* File Uploader and Camera Input Preview Styling */\n",
        ".stFileUploader, .stCameraInput {\n",
        "    border: 2px dashed #4CAF50;\n",
        "    border-radius: 12px;\n",
        "    padding: 20px;\n",
        "    text-align: center;\n",
        "    background-color: #2a2a2a;\n",
        "    transition: all 0.3s ease;\n",
        "    margin-bottom: 1.5rem;\n",
        "}\n",
        "\n",
        ".stFileUploader:hover, .stCameraInput:hover {\n",
        "    background-color: #3a3a3a;\n",
        "    border-color: #66bb6a;\n",
        "}\n",
        "\n",
        ".stImage { /* Style for displayed images */\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.5);\n",
        "    margin: 1.5rem auto; /* Center image and provide space */\n",
        "    display: block; /* Ensure margin auto works */\n",
        "    max-width: 100%;\n",
        "    height: auto;\n",
        "}\n",
        "\n",
        "/* Text and general elements */\n",
        "p, label, .stMarkdown, .css-1jc7o2r, .css-1l0bqyk, .css-1vq4p4u, .css-1qxtsq5, .css-1d391kg {\n",
        "    color: #c0c0c0;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "\n",
        "/* Success/Error messages */\n",
        ".stAlert {\n",
        "    border-radius: 8px;\n",
        "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "}\n",
        ".stAlert.success {\n",
        "    background-color: #d4edda;\n",
        "    color: #155724;\n",
        "}\n",
        ".stAlert.error {\n",
        "    background-color: #f8d7da;\n",
        "    color: #721c24;\n",
        "}\n",
        "\n",
        "/* Streamlit's main content area */\n",
        ".stApp {\n",
        "    background-color: #1a1a1a;\n",
        "}\n",
        "\n",
        "/* Responsiveness */\n",
        "@media (max-width: 768px) {\n",
        "    .main .block-container {\n",
        "        padding-left: 0.5rem;\n",
        "        padding-right: 0.5rem;\n",
        "    }\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load the pre-trained model\n",
        "MODEL_PATH = 'fruit_fresh_spoiled_model.h5'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_my_model():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "model = load_my_model()\n",
        "\n",
        "IMG_SIZE = (150, 150)\n",
        "\n",
        "def classify_fruit_streamlit(img):\n",
        "    \"\"\"Predicts whether a fruit image is fresh or spoiled.\"\"\"\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "    x = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
        "    prediction = model.predict(x)[0][0]\n",
        "\n",
        "    if prediction < 0.5:\n",
        "        label = \"ğŸ Fresh\"\n",
        "        confidence = 1 - prediction\n",
        "    else:\n",
        "        label = \"ğŸ‚ Spoiled\"\n",
        "        confidence = prediction\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# Streamlit App Layout\n",
        "st.title(\"ğŸ Fresh vs Spoiled Fruit Detector\")\n",
        "st.write(\"Upload an image of a fruit or use your camera to classify it as fresh or spoiled.\")\n",
        "\n",
        "# Input selection radio button\n",
        "input_source = st.radio(\n",
        "    \"Select input source:\",\n",
        "    ('Upload Picture', 'Camera Input'),\n",
        "    key=\"input_selector\"\n",
        ")\n",
        "\n",
        "uploaded_file = None\n",
        "camera_image = None\n",
        "\n",
        "if input_source == 'Upload Picture':\n",
        "    uploaded_file = st.file_uploader(\"Choose an image from your files...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "elif input_source == 'Camera Input':\n",
        "    camera_image = st.camera_input(\"Take a picture with your camera\")\n",
        "\n",
        "image_to_process = None\n",
        "if uploaded_file is not None:\n",
        "    image_to_process = Image.open(uploaded_file)\n",
        "elif camera_image is not None:\n",
        "    image_to_process = Image.open(camera_image)\n",
        "\n",
        "if image_to_process is not None:\n",
        "    st.image(image_to_process, caption='Selected Image', use_container_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    label, confidence = classify_fruit_streamlit(image_to_process)\n",
        "\n",
        "    st.write(\"### Prediction:\")\n",
        "    if \"Fresh\" in label:\n",
        "        st.success(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")\n",
        "    else:\n",
        "        st.error(f\"The fruit is {label} with {confidence*100:.2f}% confidence.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d573693f",
        "outputId": "70f2526f-d699-4808-fa93-edb0e19f061f"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "# Find and kill any processes named 'streamlit'\n",
        "try:\n",
        "    # List all processes and filter for streamlit\n",
        "    # os.kill is for a specific PID, ps aux | grep is better for finding by name\n",
        "    # This is a common way to kill previous streamlit processes in a Colab-like environment\n",
        "    output = subprocess.check_output(['ps', 'aux']).decode('utf-8')\n",
        "    for line in output.splitlines():\n",
        "        if 'streamlit run' in line and 'python' in line:\n",
        "            pid = int(line.split()[1])\n",
        "            subprocess.run(['kill', '-9', str(pid)])\n",
        "            print(f\"Killed Streamlit process with PID: {pid}\")\n",
        "except Exception as e:\n",
        "    print(f\"No Streamlit processes found to kill or an error occurred: {e}\")\n",
        "\n",
        "# Also kill any ngrok processes\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "print(\"âœ… ngrok processes killed.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ngrok processes killed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "d30f7d7c",
        "outputId": "6ac1178b-2808-4a7d-9df5-c93632e51625"
      },
      "source": [
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "# The app will run on port 8501 by default\n",
        "streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"streamlit_app.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "print(\"âœ… Streamlit app started in the background.\")\n",
        "\n",
        "# Wait a moment for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Establish an ngrok tunnel to the Streamlit app (port 8501)\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"âœ… ngrok tunnel established: {public_url}\")\n",
        "    print(\"You can now access your Streamlit app at the URL above.\")\n",
        "    print(\"To stop the tunnel and app, interrupt this cell (Ctrl+C).\")\n",
        "\n",
        "    # Keep the script running to maintain the tunnel\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error establishing ngrok tunnel: {e}\")\n",
        "finally:\n",
        "    # Ensure Streamlit process is terminated when the tunnel is closed or script interrupted\n",
        "    if streamlit_process.poll() is None:\n",
        "        streamlit_process.terminate()\n",
        "        print(\"âœ… Streamlit app terminated.\")\n",
        "    ngrok.kill()\n",
        "    print(\"âœ… ngrok process killed.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Streamlit app started in the background.\n",
            "âœ… ngrok tunnel established: NgrokTunnel: \"https://garnett-placeless-donna.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "You can now access your Streamlit app at the URL above.\n",
            "To stop the tunnel and app, interrupt this cell (Ctrl+C).\n",
            "âœ… Streamlit app terminated.\n",
            "âœ… ngrok process killed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4081241684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Keep the script running to maintain the tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âŒ Error establishing ngrok tunnel: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675826f2"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"fruit_fresh_spoiled_model.keras\")\n",
        "print(\"âœ… Model saved in native Keras format (fruit_fresh_spoiled_model.keras)\")"
      ],
      "metadata": {
        "id": "fWga768K-vNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3eccf8-1a0d-44c0-9841-a6669a673158"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved in native Keras format (fruit_fresh_spoiled_model.keras)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIEAfFCOxS5",
        "outputId": "3c939841-0cef-4b4c-8207-7bfdcdd99542"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzGZB5PqQE9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}